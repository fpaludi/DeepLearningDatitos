{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unidad2_Notas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMK54Qb45Rj3u+D9EkBvVzN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpaludi/DeepLearningDatitos/blob/master/Unidad2_Notas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jGaLuSS1nr2"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xM2qDCkLQJX",
        "outputId": "a747f2fd-4b07-4fb5-f8af-282ec625ac45"
      },
      "source": [
        "x = torch.arange(4.0, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj2OGvQSLWCL"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiXV-JtwLY2M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVGtUluOLZdY"
      },
      "source": [
        "$y = 2 \\times x^2$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH6nSZFzLXaB",
        "outputId": "d35aca95-cfcb-4fe9-c3f7-91e748196c71"
      },
      "source": [
        "y = 2 * torch.dot(x, x)\n",
        "y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJOnnS_iLoNy"
      },
      "source": [
        "**we can automatically calculate the gradient of y with respect to each component of x] by calling the function for backpropagation and printing the gradient.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GtVPXqDLi1M",
        "outputId": "a3371ea7-61a8-4552-efd3-573981687718"
      },
      "source": [
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf3rS0zQLtyL"
      },
      "source": [
        "$y' = 4 \\times x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4repsyAN1u6O"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q69IOCSXL1-4",
        "outputId": "c18b1820-02a1-4755-a5f7-265691ac3fac"
      },
      "source": [
        "x.grad == 4 * x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDwoJPr5L2TY",
        "outputId": "25ec4491-af52-4d0c-a41c-c1872603f712"
      },
      "source": [
        "all(x.grad == 4 * x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGwcFW44L9Ho"
      },
      "source": [
        "**Now let us calculate another function of `x`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fBsUrDIL4ko",
        "outputId": "a3a49503-2563-4569-d189-beeab68c15de"
      },
      "source": [
        "x.grad.zero_()\n",
        "y = x.sum()\n",
        "y.backward()\n",
        "x.grad"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg3mgeLHMIYF"
      },
      "source": [
        "## Backward for Non-Scalar Variables\n",
        "Technically, when y is not a scalar, the most natural interpretation of the differentiation of a vector y with respect to a vector x is a matrix. For higher-order and higher-dimensional y and x, the differentiation result could be a high-order tensor.\n",
        "\n",
        "However, while these more exotic objects do show up in advanced machine learning (including [in deep learning]), more often (when we are calling backward on a vector,) we are trying to calculate the derivatives of the loss functions for each constituent of a batch of training examples. Here, (our intent is) not to calculate the differentiation matrix but rather (the sum of the partial derivatives computed individually for each example) in the batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8G1ENefL-mM",
        "outputId": "d20b1c82-0fe6-4fd6-f4fc-f17b0508ebc3"
      },
      "source": [
        "# Invoking `backward` on a non-scalar requires passing in a `gradient` argument\n",
        "# which specifies the gradient of the differentiated function w.r.t `self`.\n",
        "# In our case, we simply want to sum the partial derivatives, so passing\n",
        "# in a gradient of ones is appropriate\n",
        "x.grad.zero_()\n",
        "y = x * x\n",
        "# y.backward(torch.ones(len(x))) equivalent to the below\n",
        "y.sum().backward()\n",
        "x.grad"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJscRkFUMjbD"
      },
      "source": [
        "## Computing the Gradient of Python Control Flow\n",
        "One benefit of using automatic differentiation is that [even if] building the computational graph of (a function required passing through a maze of Python control flow) (e.g., conditionals, loops, and arbitrary function calls), (we can still calculate the gradient of the resulting variable.) In the following snippet, note that the number of iterations of the while loop and the evaluation of the if statement both depend on the value of the input a."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVxCpL0FMZEi"
      },
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUcXiVpSMmqU"
      },
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TJ3a9kCMxHu",
        "outputId": "e1322b94-9fab-49d4-ccfc-725af57d1fa6"
      },
      "source": [
        "a.grad == d / a"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYkuA26PPVLr",
        "outputId": "6b8cbb47-a97e-4273-c061-f91474f534e2"
      },
      "source": [
        "a, a.grad, d"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4676, requires_grad=True),\n",
              " tensor(4096.),\n",
              " tensor(1915.1417, grad_fn=<MulBackward0>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpeAstUYPcJl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}